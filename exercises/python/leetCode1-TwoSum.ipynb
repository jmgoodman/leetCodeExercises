{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"leetCode1-TwoSum.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNAvTHVi4tp1P2q7ppZyBT0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Uj-uEjfLjOKP"},"outputs":[],"source":["class Solution:\n","    def twoSum(self, nums: List[int], target: int) -> List[int]:\n","        # find the minimum number in the input list (or not, maybe this just is slower than the time it saves)\n","        # minval = min(nums)\n","        \n","        # find all values less than or equal to target - min (or not, maybe this just is slower than the time it saves\n","        # in fact it DEFINITELY is, since nothing constrains the inputs to be positive...\n","        # cutoff = target - minval\n","        # inds2test = [idx for idx,val in enumerate(nums) if val<=cutoff]\n","        \n","        # now just do an exhaustive search, maybe there's a fancy math way to do it faster...\n","        for idx0,val0 in enumerate(nums):\n","            startidx = idx0+1\n","            for idx1,val1 in enumerate(nums[startidx:]):\n","                testval = val0 + val1\n","                if testval == target:\n","                    return [idx0,idx1+startidx]\n","                else:\n","                    pass\n","                \n","        # now how about the solution that's less than O(n2) time complexity?\n","        # ah okay, the hash table. that would run in 2n time instead of 0.5 n**2 time\n","        # except... isn't checking \"if complement in hashmap\" itself running in O(n) time?\n","        # NO, it's implicitly using a hash that lets it just look up an entry in a membership table\n","        # (how's that work? well, a hash table has a CONSTANT overhead, albeit a large one, so it's dwarfed long-term by any n terms)"]},{"cell_type":"markdown","source":["Efficient Solution: Hash Tables to go from O(n**2) to O(n) time (with buffer overhead + O(n) space complexity)"],"metadata":{"id":"3JpJVD7zo3hS"}},{"cell_type":"markdown","source":["Approach 3: One-pass Hash Table\n","Algorithm\n","\n","It turns out we can do it in one-pass. While we are iterating and inserting elements into the hash table, we also look back to check if current element's complement already exists in the hash table. If it exists, we have found a solution and return the indices immediately."],"metadata":{"id":"-3zPzqgypFSP"}},{"cell_type":"code","source":["class Solution:\n","    def twoSum(self, nums: List[int], target: int) -> List[int]:\n","        hashmap = {}\n","        for i in range(len(nums)):\n","            complement = target - nums[i]\n","            if complement in hashmap:\n","                return [i, hashmap[complement]]\n","            hashmap[nums[i]] = i"],"metadata":{"id":"bjM0ytZxpD4S"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Complexity Analysis\n","\n","Time complexity: O(n). We traverse the list containing n elements only once. Each lookup in the table costs only O(1) time.\n","\n","Space complexity: O(n). The extra space required depends on the number of items stored in the hash table, which stores at most n elements."],"metadata":{"id":"me7mwY_hpL8h"}},{"cell_type":"markdown","source":["# alternate solution with try-except (somehow faster? python you weird)"],"metadata":{"id":"3FLRrEmV5n-_"}},{"cell_type":"code","source":["class Solution:\n","    def twoSum(self, nums: List[int], target: int) -> List[int]:\n","        # let's maintain that hash table (dict) of values then\n","        # single-pass solution\n","        # without using the template\n","        hashtable = dict()\n","        for idx,val in enumerate(nums):\n","            complement = target-val\n","            # lets do it without builtin hash table testing methods\n","            # this will invoke error handling most likely, making it slower, but...\n","            # wait... what? omg how is this faster than x in y?\n","            # are the overwhelming majority of cases valid keys?\n","            # or is the interpreter just wicked smart now and knows to avoid invoking the error handler for a structure like this?\n","            try:\n","                return [hashtable[complement],idx]\n","            except:\n","                hashtable[val] = idx  # additional time could be saved by only computing complements to use as keys in this stage"],"metadata":{"id":"7XXp882X5qur"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Raw hash table implementation"],"metadata":{"id":"xIaE5zEW5sKq"}},{"cell_type":"markdown","source":["Don't waste your time. \n","\n","You get the basic concept (init a buffer array, generate memory addresses within this table from arbitrary keys using a hash function, store pointers to values in this table, in the unlikely case of collisions these pointers will come to point to linked lists of key-value pairs instead of single values, then forcing search / retrieval / insertion for such collisions to expand to classic brute-force O(n) complexity). \n","\n","Namely, retrieval/lookup are reduced from O(n) complexity (check all memory addresses bound to your array til you get a matching key) to O(1) complexity (you know beforehand what address the value associated with the key should be stored in, thanks to the hashing function, so just look there).\n","\n","In no situation will you ever have to make this from scratch. There will ALWAYS be vetted tools that abstract this stuff away from you."],"metadata":{"id":"dUHR-xo45uhq"}},{"cell_type":"markdown","source":["# The BEST submission (maybe, in the end probably not meaningfully different from what I implemented dict-wise)"],"metadata":{"id":"JEzhZWLGAv-c"}},{"cell_type":"code","source":["class Solution:\n","    def twoSum(self, nums: List[int], target: int) -> List[int]:\n","        # copy-paste of the fastest solution to test if there's just a hardware limitation because I'm not paying for anything or smth\n","        # okay yeah this is faster than anything I was doing (60ms) by about 10ms (52ms to be precise) \n","        # but still about 10ms slower than the official score (40ms)\n","        # not sure why it's faster though. \n","        # probably something to do with enumerate? \n","        # something to do with when we bother to compute the complement? \n","        # and whether to use the complement as a query or a key?\n","        # it also looks like parsing comments also slows things down quite a bit\n","        # actually, the more I tested it, the more unreliable it seemed \n","        # and the more those extra 10-20ms looked like the vagarities of which hardware my job was pushed to\n","        # or how quickly the server was able to get to work on my request\n","        # or whether my submission requests were being throttled because I'm not paying for premium / was submitting a lot of requests in a short time period\n","        # and less to do with the algorithm per se\n","        seen = {}\n","        \n","        for i in range(len(nums)):\n","            if (target - nums[i]) in seen:\n","                return [seen[target - nums[i]], i]\n","            else:\n","                seen[nums[i]] = i"],"metadata":{"id":"0ZIvOakUAyKc"},"execution_count":null,"outputs":[]}]}